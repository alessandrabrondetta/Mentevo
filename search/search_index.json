{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>\ud83d\udc4b  Mentevo is a compact library designed for studying the dynamic of balancing cognitive stability and flexibility in groups of agents, initially providing the implementation code for the research paper of Brondetta et al, 2023.</p> <p>This repository also introduces various parametrization, visualization methods as well as metrics to compute performances of each agents. However, Mentevo emphasizes experimentation and is not an official reproduction of any other paper aside from Brondetta et al.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To start with Mentevo, we propose multiple notebook that will help you familiarize with the library</p> <ul> <li>Starter </li> <li>Study of optimal gain value depending on the task switching rate </li> <li>Performance in details </li> <li>Partially informed agents </li> </ul> <p>Otherwise, you can simply start hacking with mentevo, it's as simple as:</p> <pre><code>from mentevo import (Experiment, compute_performance, plot_curves)\n\n# create an experiment object\nexperiment = Experiment(nb_agents=4)\nsimulation_results = experiment.solve()\n\n# plots the simulation results\nplot_curves(experiment, simulation_results)\n\n# compute the performance\nscores = compute_performance(experiment, simulation_results)\nprint('individual performance', scores[0])\nprint('group performance', scores[1])\n</code></pre> <p>When optimizing, it's crucial to fine-tune the hyperparameters. Parameters like the alpha, beta, d or tau significantly impact the output. We recommend ajusting the values according to the original paper to ensure comparable results.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@inproceedings{brondetta2024benefits,\n  title={On the Benefits of Heterogeneity in Cognitive Stability and Flexibility for Collaborative Task Switching},\n  author={Brondetta, Alessandra and Bizyaeva, Anastasia and Lucas, Maxime and Petri, Giovanni and Musslick, Sebastian},\n  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},\n  volume={46},\n  year={2024}\n}\n</code></pre>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Alessandra Brondetta - alessandra.brondetta@uni-osnabrueck.de, Candidate PhD Student under the supervision of Prof. Sebastian Musslick, Automated Scientific Discovery of Mind and Brain, Osnabr\u00fcck University.</li> </ul>"},{"location":"experiments/","title":"Experiment","text":"<p>You can write text here.</p> <pre><code>this is some python code\n</code></pre> <p>Todo this documentation</p>"},{"location":"experiments/#Experiment","title":"<code>Experiment</code>","text":"<p>Class to represent an experiment. This Experiment class models and simulates a system with  interacting agents and tasks, solving a nonlinear dynamical system defined by agent behaviors,  communication structure and task correlations, system parameters and external inputs. The Experiment class simulates the evolution of the task activities of the agents over time, and is also defined by the initial state of the system and the parameters of the  simulation, such as total time of the simulation and number of task switches.  The class contains a solver for simulating system evolution over time. </p>"},{"location":"experiments/#__init__","title":"<code>__init__(self,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents=4,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks=2,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 communication_graph=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_graph=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 alpha=0.03,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 beta=0.01,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 gamma=0.02,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta=0.0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 d=0.2,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 tau=10.0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 g=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 bias_value=0.1,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_state=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 total_time=2000,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_steps=0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 reverse=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_switches=4,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_informed=None)</code>","text":"<p>Parameters</p> <ul> <li> <p>number_of_agents            : int, optional </p> <ul> <li><p> Number of agents in the system. Must be greater than 0. Default is 4. </p> </li> </ul> </li> <li> <p>number_of_tasks            : int, optional </p> <ul> <li><p> Number of tasks the agents have to perform. Must be greater than 0. Default is 2.</p> </li> </ul> </li> <li> <p>communication_graph            : 2D numpy array, optional </p> <ul> <li><p> The graph between agents. A positive value means that the agents have a positive interaction,  a negative value means that the agents have a negative interaction. A null value means that  the agents can not communicate.    Typically, the diagonal is 1 (intra-agent-communication).</p><p> If None, then the default is a fully connected graph where all agents can communicate.</p><p> The shape of the matrix is (number_of_agents, number_of_agents).</p> </li> </ul> </li> <li> <p>task_graph            : 2D numpy array, optional </p> <ul> <li><p> The graph between tasks. A positive value means that the tasks are positively correlated,  a negative value means that the tasks are negatively correlated. A null value means that  the tasks are not correlated.</p><p> Typically, the diagonal is 1 (same-task correlation).  If None, then the default is diagonal 1 (positive self correlation) and  off-diagonal values are -1 (negative correlations with the other tasks).</p><p> The shape of the matrix is (number_of_tasks, number_of_tasks). </p> </li> </ul> </li> <li> <p>alpha            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the same agent- same task interactions. Must be greater than or equal to 0. Default is 0.03.  </p> </li> </ul> </li> <li> <p>beta            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the same agent- different task interactions. Must be greater than or equal to 0. Default is 0.01. </p> </li> </ul> </li> <li> <p>gamma            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the different agent- same task interactions. Must be greater than or equal to 0. Default is 0.02. </p> </li> </ul> </li> <li> <p>delta            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the different agent- different task interactions. Must be greater than or equal to 0. Default is 0.0. </p> </li> </ul> </li> <li> <p>d            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the decay term.</p><p> Must be greater than or equal to 0. Default is 0.2.    </p> </li> </ul> </li> <li> <p>tau            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the time constant.  Must be greater than 0. Default is 10.0.</p> </li> </ul> </li> <li> <p>g            : 1D numpy array, optional </p> <ul> <li><p> The g vector of the dynamical system's equations, representing the gain values of the agents  and regulating the slope of the saturation function.  The shape of the array is (number_of_agents,).</p><p> Default is a gaussian vector with mean 3.0 and standard deviation 1.0. </p> </li> </ul> </li> <li> <p>bias_value            : float, optional </p> <ul> <li><p> The bias value of the dynamical system's equations that represents the weight of the cue  vector of the experiment. Must be greater than or equal to 0. Default is 0.1.</p> </li> </ul> </li> <li> <p>initial_state            : 1D numpy array, optional </p> <ul> <li><p> The initial state of the system, representing the task activity states at the start of the experiment. The shape of the array is (number_of_agents*number_of_tasks,).</p><p> Default is an array of zero for all agents on all tasks.</p> </li> </ul> </li> <li> <p>total_time            : int, optional </p> <ul> <li><p> The total time of the simulation in time units. Must be greater than 0. Default is 2_000. </p> </li> </ul> </li> <li> <p>initial_steps            : int, optional </p> <ul> <li><p> The number of initial steps in the experiment, where the agents don't receive the task cue.  Must be greater than or equal to 0. Must be less than total_time. Default is 0.</p> </li> </ul> </li> <li> <p>reverse            : bool, optional </p> <ul> <li><p> If True, the task cue vector is reversed in the experiment. Default is False.</p> </li> </ul> </li> <li> <p>number_of_switches            : int, optional </p> <ul> <li><p> The number of task switches in the experiment. Must be greater than or equal to 0.  Must be less than or equal to total_time. Must be greater than or equal to 0. Default is 4.</p> </li> </ul> </li> <li> <p>number_of_informed            : int, optional </p> <ul> <li><p> The number of agents that are informed in the experiment (agents that receive the task cue vector). Must be less than or equal to number_of_agents and non-negative.</p><p> Default is number_of_agents. </p> </li> </ul> </li> </ul>"},{"location":"experiments/#solve","title":"<code>solve(self,\u00a0\u00a0\u00a0\u00a0\u00a0 **kwargs)</code>","text":"<p>Solve the dynamical system defined by the experiment's parameters and initial state.  The system is solved using the scipy solve_ivp function. The system is solved for the total time of the experiment, with a maximum step of 1_000 and using the Radau  integration method. The system is solved for each time unit, and the task activity states of the agents are returned over time in the experiment. </p> <p>Parameters</p> <ul> <li> <p>kwargs            : dictionary, optional </p> <ul> <li><p> Additional keyword arguments to pass to the solve_ivp function.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>zs.y            : 2D numpy array </p> <ul> <li><p> The task activity states of the agents over time in the experiment.</p><p> The shape of the array is (number_of_agents*number_of_tasks, total_time).</p> </li> </ul> </li> </ul> <p></p>"},{"location":"performance/","title":"Performance","text":"<p>You can write text here.</p> <pre><code>this is some python code\n</code></pre> <p>Todo this documentation</p>"},{"location":"performance/#compute_performance","title":"<code>compute_performance(experiment,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 simulation_results,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 detailed=False)</code>","text":"<p>Compute the performance of the agents in the experiment using the simulation results. The metric used is the dot product between the sign of cue vector and the simulation results,  indeed counting in a positive way the areas where the agent is focusing more on the correct task and in a negative way  the areas where the agent is doing the wrong task.  The individual performance is the sum of the scores of each agent on both tasks. The group performance is simply the sum of the scores of all agents. This function works only for experiments with two tasks. </p> <p>Parameters</p> <ul> <li> <p>experiment            : Experiment </p> <ul> <li><p> The experiment object that generated the simulation_results.</p> </li> </ul> </li> <li> <p>simulation_results            : 2D numpy array </p> <ul> <li><p> The simulation results used to compute the performance.  The shape should be (number_of_agents * number_of_tasks, total_time).</p> </li> </ul> </li> <li> <p>detailed            : bool, optional </p> <ul> <li><p> Whether to return detailed information about the performance (performance values at each time step). The default is False.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>individual_performance            : 1D numpy array </p> <ul> <li><p> The performance of each agent. The shape is (number_of_agents,).</p> </li> </ul> </li> <li> <p>group_performance            : float </p> <ul> <li><p> The performance of the group.</p> </li> </ul> </li> <li> <p>detailed_score.T            : 2D numpy array </p> <ul> <li><p> The performance of each agent, at each time step, on each task.  The shape is (number_of_agents*number_of_tasks, total_time).</p><p> This is returned only if detailed=True.  </p> </li> </ul> </li> <li> <p>individual_performance_t            : 1D numpy array </p> <ul> <li><p> The performance of each agent on the two different tasks, sum over time.  The shape is (number_of_agents*number_of_tasks,).</p><p> This is returned only if detailed=True. </p> </li> </ul> </li> </ul> <p></p>"},{"location":"plots/","title":"Plots","text":"<p>You can write text here.</p> <pre><code>this is some python code\n</code></pre> <p>Todo this documentation</p>"},{"location":"plots/#plot_curves","title":"<code>plot_curves(experiment,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 simulation_results,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 title=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 x_label=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 y_label=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_labels=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_legend=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_location='inside',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_fontsize=10,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_vertical_lines=True,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_linewidth=1,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_line_color='black',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_line_style='--',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_cue_vector=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 **kwargs)</code>","text":"<p>Plots simulation curves for a two-task experiment, specifically the time evolution of the  difference between the two task activities for each agent. </p> <p>Parameters</p> <ul> <li> <p>experiment            : Experiment </p> <ul> <li><p> The experiment object that generated the simulation_results.</p> </li> </ul> </li> <li> <p>simulation_results            : 2D numpy array </p> <ul> <li><p> The simulation results use to create the plot.  The shape should be (number_of_agents * number_of_tasks, total_time).</p> </li> </ul> </li> <li> <p>title            : str, optional </p> <ul> <li><p> The title of the plot. The default is None.</p> </li> </ul> </li> <li> <p>x_label            : str, optional </p> <ul> <li><p> The x-axis label. The default is None.</p> </li> </ul> </li> <li> <p>y_label            : str, optional </p> <ul> <li><p> The y-axis label. The default is None.</p> </li> </ul> </li> <li> <p>legend_labels            : list of str, optional </p> <ul> <li><p> The labels for the legend. The default 'Agent i+1' whit i in range(number_of_agents).</p> </li> </ul> </li> <li> <p>show_legend            : bool, optional </p> <ul> <li><p> Whether to show the legend. The default is False (the legend is not shown).</p> </li> </ul> </li> <li> <p>legend_location            : str, optional </p> <ul> <li><p> The location of the legend. The default is 'inside' (the legend is inside the plot).  If 'outside', the legend is outside the plot.</p> </li> </ul> </li> <li> <p>legend_fontsize            : int, optional </p> <ul> <li><p> The font size of the legend. The default is 10.</p> </li> </ul> </li> <li> <p>show_vertical_lines            : bool, optional </p> <ul> <li><p> Whether to show vertical lines for task-switching times. The default is True (the vertical lines are plotted).</p> </li> </ul> </li> <li> <p>task_switching_linewidth            : int, optional </p> <ul> <li><p> The width of the task-switching vertical lines. The default is 1.</p> </li> </ul> </li> <li> <p>task_switching_line_color            : str, optional </p> <ul> <li><p> The color of the task-switching vertical lines. The default is 'black'. </p> </li> </ul> </li> <li> <p>task_switching_line_style            : str, optional </p> <ul> <li><p> The line style of the task-switching vertical lines. The default is '--'.</p> </li> </ul> </li> <li> <p>show_cue_vector            : bool, optional </p> <ul> <li><p> Whether to plot the cue vector. The default is False (the cue vector is not plotted).</p> </li> </ul> </li> <li> <p>kwargs            : dictionary, optional </p> <ul> <li><p> Additional keyword arguments to pass to the plot function (e.g., color, linestyle, etc.).</p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/","title":"Utils","text":"<p>You can write text here.</p> <pre><code>this is some python code\n</code></pre> <p>Todo this documentation</p>"},{"location":"utils/#gaussian_g_vector","title":"<code>gaussian_g_vector(average,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 deviation,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents)</code>","text":"<p>Create a vector of g values following Gaussian distribution. The average value of the vector is forced to be the average value given as input. </p> <p>Parameters</p> <ul> <li> <p>average            : float </p> <ul> <li><p> The average value of the Gaussian distribution.</p><p> The average should be greater than 0.0.</p> </li> </ul> </li> <li> <p>deviation            : float </p> <ul> <li><p> The standard deviation of the Gaussian distribution.</p><p> The deviation should be non-negative.</p> </li> </ul> </li> <li> <p>number_of_agents            : int </p> <ul> <li><p> The number of agents in the system.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>g            : 1D numpy array </p> <ul> <li><p> A numpy array of size (number_of_agents,) with the g values for all agents in the system.           </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#uniform_g_vector","title":"<code>uniform_g_vector(average,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents)</code>","text":"<p>Create a vector of g values following uniform distribution. The average value of the vector is forced to be the average value given as input. </p> <p>Parameters</p> <ul> <li> <p>average            : float </p> <ul> <li><p> The average value of the uniform distribution.</p><p> The average should be greater than 0.0.</p> </li> </ul> </li> <li> <p>delta            : float </p> <ul> <li><p> The deviation of the uniform distribution.</p><p> The deviation should be non-negative. The deviation should be less or equal to the average.</p> </li> </ul> </li> <li> <p>number_of_agents            : int </p> <ul> <li><p> The number of agents in the system.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>g            : 1D numpy array </p> <ul> <li><p> A numpy array of size (number_of_agents,) with the g values for all agents in the system.           </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#build_forward_matrix","title":"<code>build_forward_matrix(number_of_agent,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 alpha,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 beta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 gamma,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_graph,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 communication_graph)</code>","text":"<p>Build the forward matrix of the homogeneous system, where the parameter alpha, beta,  gamma and delta are the same for all the agents. </p> <p>Parameters</p> <ul> <li> <p>number_of_agent            : int </p> <ul> <li><p> Number of agents in the system. The number of agents should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_tasks            : int </p> <ul> <li><p> Number of tasks the agents have to perform. The number of tasks should be greater than 0.</p> </li> </ul> </li> <li> <p>alpha            : float </p> <ul> <li><p> The scalar value that weights the same agent-same task interaction. The value should be  non-negative.</p> </li> </ul> </li> <li> <p>beta            : float </p> <ul> <li><p> The scalar value that weights the same agent-different task interaction.</p><p> The value should be non-negative.    </p> </li> </ul> </li> <li> <p>gamma            : float </p> <ul> <li><p> The scalar value that weights the different agent-same task interaction.</p><p> The value should be non-negative.</p> </li> </ul> </li> <li> <p>delta            : float </p> <ul> <li><p> The scalar value that weights the different agent-different task interaction.    The value should be non-negative.</p> </li> </ul> </li> <li> <p>task_graph            : 2D numpy array </p> <ul> <li><p> The graph between tasks. A positive value means that the tasks are positively correlated,  a negative value means that the tasks are negatively correlated.  A null value means that the tasks are not correlated.</p><p> The task graph should be of size (No, No).</p> </li> </ul> </li> <li> <p>communication_graph            : 2D numpy array </p> <ul> <li><p> The graph between agents. A positive value means that the agents have a positive interaction,  a negative value means that the agents have a negative interaction.  A null value means that the agents can not communicate.</p><p> The communication graph should be of size (Na, Na).</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>F            : 2D numpy array </p> <ul> <li><p> The forward matrix of the system representing the interactions  between agents and tasks. The forward matrix is of size (Na * No, Na * No). </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#build_cue_vector","title":"<code>build_cue_vector(number_of_agents,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_informed,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_switches,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 total_time,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_steps=0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 reversed=False)</code>","text":"<p>Build the cue vector for the experiment. The cue vector is a 2D vector of size (total_time, Na * No) that informs the agents about the tasks  they should perform at each time unit. Na is the number of agents and No is the number of tasks. The cue vector has the following characteristics: </p> <p>Parameters</p> <ul> <li> <p>number_of_agents            : int </p> <ul> <li><p> Number of agents in the system. The number of agents should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_tasks            : int </p> <ul> <li><p> Number of tasks the agents have to perform. The number of tasks should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_informed            : int </p> <ul> <li><p> Number of agents that are informed about the tasks (that receive the task cue).  The number of informed agents should be non-negative and less than or equal to the number  of agents.</p> </li> </ul> </li> <li> <p>number_of_switches            : int </p> <ul> <li><p> Number of switches in the cue vector.</p><p> The number of switches should be non-negative.</p><p> The number of switches should be less than or equal to total_time - initial_steps.</p> </li> </ul> </li> <li> <p>total_time            : int </p> <ul> <li><p> Total time of the experiment in time units. The total time should be greater than 0.</p> </li> </ul> </li> <li> <p>initial_steps            : int, optional </p> <ul> <li><p> Number of initial time steps where no task is prioritized.  The number of initial steps should be non-negative.</p><p> The number of initial steps should be less than or equal to total_time.</p><p> Default is 0.</p> </li> </ul> </li> <li> <p>reversed            : bool, optional </p> <ul> <li><p> This options is used to reverse the cue vector. If True, the cue vector is reversed.</p><p> Default is False.  </p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>cue_vector            : 2D numpy array </p> <ul> <li><p> The cue vector of the experiment. The cue vector is of size (total_time, Na * No).</p> </li> </ul> </li> </ul> <p></p>"}]}