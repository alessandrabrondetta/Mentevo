{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>\ud83d\udc4b  Mentevo is a compact library designed for studying the dynamic of balancing cognitive stability and flexibility in task-switching environments within groups of agents, initially providing the implementation code for the research paper of Brondetta et al, 2024.</p> <p>This repository also introduces various parametrization, visualization methods as well as metrics to compute performances of each agents. However, Mentevo emphasizes experimentation and is not an official reproduction of any other paper aside from Brondetta et al.</p>"},{"location":"#getting-started","title":"Getting Started","text":"<p>To start with Mentevo, we propose multiple notebook that will help you familiarize with the library:</p> <ul> <li>Starter </li> <li>Simulation examples </li> <li>Performance metric in details </li> <li>Study of optimal gain value depending on the task switching rate </li> </ul> <p>Otherwise, you can simply start hacking with mentevo, it's as simple as:</p> <pre><code>from mentevo import (Experiment, compute_performance, plot_curves)\n\n# create an experiment object\nexperiment = Experiment(nb_agents=4)\nsimulation_results = experiment.solve()\n\n# plots the simulation results\nplot_curves(experiment, simulation_results)\n\n# compute the performance\nscores = compute_performance(experiment, simulation_results)\nprint('individual performance', scores[0])\nprint('group performance', scores[1])\n</code></pre> <p>When optimizing, it's crucial to fine-tune the hyperparameters. Parameters like the alpha, beta, d or tau significantly impact the output. We recommend ajusting the values according to the original paper to ensure comparable results.</p>"},{"location":"#citation","title":"Citation","text":"<pre><code>@inproceedings{brondetta2024benefits,\n  title={On the Benefits of Heterogeneity in Cognitive Stability and Flexibility for Collaborative Task Switching},\n  author={Brondetta, Alessandra and Bizyaeva, Anastasia and Lucas, Maxime and Petri, Giovanni and Musslick, Sebastian},\n  booktitle={Proceedings of the Annual Meeting of the Cognitive Science Society},\n  volume={46},\n  year={2024}\n}\n</code></pre>"},{"location":"#authors","title":"Authors","text":"<ul> <li>Alessandra Brondetta, PhD Student under the supervision of Prof. Dr. Sebastian Musslick, Automated Scientific Discovery of Mind and Brain, Osnabr\u00fcck University.</li> </ul>"},{"location":"#contact","title":"Contact","text":"<p>If you have any feedback, questions or suggestions, feel free to contact: </p> <p>\ud83d\udce7 albrondetta@uni-osnabrueck.de</p>"},{"location":"experiments/","title":"Experiment","text":"<p>This document describes the Experiment class, which simulates the evolution of task activities for multiple agents performing multiple tasks. The model is a nonlinear dynamical system with structured interactions and an external task cue.</p>"},{"location":"experiments/#-","title":"------------------------------------","text":""},{"location":"experiments/#Experiment","title":"<code>Experiment</code>","text":"<p>Class to represent an experiment. This Experiment class models and simulates a system with  interacting agents and tasks, solving a nonlinear dynamical system defined by agent behaviors,  communication structure and task correlations, system parameters and external inputs. The Experiment class simulates the evolution of the task activities (agents' focus) of the  agents over time, and is also defined by the initial state of the system and the parameters  of the simulation, such as total time of the simulation and number of task switches.  The class contains a solver for simulating system evolution over time. </p>"},{"location":"experiments/#__init__","title":"<code>__init__(self,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents=4,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks=2,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 communication_graph=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_graph=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 alpha=0.03,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 beta=0.01,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 gamma=0.02,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta=0.0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 d=0.2,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 tau=10.0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 g=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 bias_value=0.1,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_state=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 total_time=2000,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_steps=0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 reverse=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_switches=4,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_informed=None)</code>","text":"<p>Parameters</p> <ul> <li> <p>number_of_agents            : int, optional </p> <ul> <li><p> Number of agents in the system. Must be greater than 0. Default is 4. </p> </li> </ul> </li> <li> <p>number_of_tasks            : int, optional </p> <ul> <li><p> Number of tasks the agents have to perform. Must be greater than 0. Default is 2.</p> </li> </ul> </li> <li> <p>communication_graph            : 2D numpy array, optional </p> <ul> <li><p> The graph between agents. A positive value means that the agents have a positive interaction,  a negative value means that the agents have a negative interaction. A null value means that  the agents can not communicate.    Typically, the diagonal is 1 (intra-agent-communication).</p><p> If None, then the default is a fully connected graph where all agents can communicate.</p><p> The shape of the matrix is (number_of_agents, number_of_agents).</p> </li> </ul> </li> <li> <p>task_graph            : 2D numpy array, optional </p> <ul> <li><p> The graph between tasks. A positive value means that the tasks are positively correlated,  a negative value means that the tasks are negatively correlated. A null value means that  the tasks are not correlated.</p><p> Typically, the diagonal is 1 (same-task correlation).  If None, then the default is diagonal 1 (positive self correlation) and  off-diagonal values are -1 (negative correlations with the other tasks).</p><p> The shape of the matrix is (number_of_tasks, number_of_tasks). </p> </li> </ul> </li> <li> <p>alpha            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the same agent- same task interactions. Must be greater than or equal to 0. Default is 0.03.  </p> </li> </ul> </li> <li> <p>beta            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the same agent- different task interactions. Must be greater than or equal to 0. Default is 0.01. </p> </li> </ul> </li> <li> <p>gamma            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the different agent- same task interactions. Must be greater than or equal to 0. Default is 0.02. </p> </li> </ul> </li> <li> <p>delta            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the different agent- different task interactions. Must be greater than or equal to 0. Default is 0.0. </p> </li> </ul> </li> <li> <p>d            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the weight of the decay term.</p><p> Must be greater than or equal to 0. Default is 0.2.    </p> </li> </ul> </li> <li> <p>tau            : float, optional </p> <ul> <li><p> Parameter of the dynamical system's equations that represents the time constant.  Must be greater than 0. Default is 10.0.</p> </li> </ul> </li> <li> <p>g            : 1D numpy array, optional </p> <ul> <li><p> The g vector of the dynamical system's equations, representing the gain values of the agents  and regulating the slope of the saturation function.  The shape of the array is (number_of_agents,).</p><p> Default is a gaussian vector with mean 3.0 and standard deviation 1.0. </p> </li> </ul> </li> <li> <p>bias_value            : float, optional </p> <ul> <li><p> The bias value of the dynamical system's equations that represents the weight of the cue  vector of the experiment. Must be greater than or equal to 0. Default is 0.1.</p> </li> </ul> </li> <li> <p>initial_state            : 1D numpy array, optional </p> <ul> <li><p> The initial state of the system, representing the task activity states at the start of the experiment. The shape of the array is (number_of_agents*number_of_tasks,).</p><p> Default is an array of zero for all agents on all tasks.</p> </li> </ul> </li> <li> <p>total_time            : int, optional </p> <ul> <li><p> The total time of the simulation in time units. Must be greater than 0. Default is 2_000. </p> </li> </ul> </li> <li> <p>initial_steps            : int, optional </p> <ul> <li><p> The number of initial steps in the experiment, where the agents don't receive the task cue.  Must be greater than or equal to 0. Must be less than total_time. Default is 0.</p> </li> </ul> </li> <li> <p>reverse            : bool, optional </p> <ul> <li><p> If True, the task cue vector is reversed in the experiment. Default is False.</p><p> This option is only for experiments with 2 tasks.</p> </li> </ul> </li> <li> <p>number_of_switches            : int, optional </p> <ul> <li><p> The number of task-cue switches in the experiment. Must be greater than 0.  Must be less than or equal to total_time. Default is 4.</p><p> The first switch correspond to the start of the experiment and  occurs at time unit 0 if initial_steps is 0, otherwise at time unit initial_steps.</p><p> Attention: the number of switches corresponds to the number of switches in the task cue vector and correspond to the number of blocks of tasks in the experiment, and is different from the number of task-to-task switches (which is number_of_switches - 1).</p> </li> </ul> </li> <li> <p>number_of_informed            : int, optional </p> <ul> <li><p> The number of agents that are informed in the experiment (agents that receive the task cue vector). Must be less than or equal to number_of_agents and non-negative.</p><p> Default is number_of_agents. </p> </li> </ul> </li> </ul>"},{"location":"experiments/#solve","title":"<code>solve(self,\u00a0\u00a0\u00a0\u00a0\u00a0 **kwargs)</code>","text":"<p>Solve the dynamical system defined by the experiment's parameters and initial state.  The system is solved using the scipy solve_ivp function. The system is solved for the total time of the experiment, with a maximum step of 1_000 and using the Radau  integration method. The system is solved for each time unit, and the task activity states of the agents are returned over time in the experiment. </p> <p>Parameters</p> <ul> <li> <p>kwargs            : dictionary, optional </p> <ul> <li><p> Additional keyword arguments to pass to the solve_ivp function.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>zs.y            : 2D numpy array </p> <ul> <li><p> The task activity states of the agents over time in the experiment.</p><p> The shape of the array is (number_of_agents*number_of_tasks, total_time).</p> </li> </ul> </li> </ul> <p></p>"},{"location":"metrics/","title":"Metrics","text":"<p>This module provides a function to score how well agents follow the externally provided cue over time.</p>"},{"location":"metrics/#-","title":"------------------------------------","text":""},{"location":"metrics/#compute_performance","title":"<code>compute_performance(experiment,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 simulation_results,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 detailed=False)</code>","text":"<p>Compute the performance of the agents in the experiment using the simulation results. The metric used is the dot product between the sign of cue vector and the simulation results,  indeed counting in a positive way the areas where the agent is focusing more on the correct task and in a negative way  the areas where the agent is doing the wrong task.  The individual performance is the sum of the scores of each agent on both tasks. The group performance is simply the sum of the scores of all agents. </p> <p>Parameters</p> <ul> <li> <p>experiment            : Experiment class object </p> <ul> <li><p> The experiment object that generated the simulation_results.</p> </li> </ul> </li> <li> <p>simulation_results            : 2D numpy array </p> <ul> <li><p> The simulation results used to compute the performance.  The shape should be (number_of_agents * number_of_tasks, total_time).  The order is [agent1_task1, agent1_task2, agent2_task1, agent2_task2, ...] in case of two agents and two tasks.</p> </li> </ul> </li> <li> <p>detailed            : bool, optional </p> <ul> <li><p> Whether to return detailed information about the performance (performance values at each time step). The default is False.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>individual_performance            : 1D numpy array </p> <ul> <li><p> The performance of each agent. The shape is (number_of_agents,).</p> </li> </ul> </li> <li> <p>group_performance            : float </p> <ul> <li><p> The performance of the group.</p> </li> </ul> </li> <li> <p>detailed_score.T            : 2D numpy array </p> <ul> <li><p> The performance of each agent, at each time step, on each task.  The shape is (number_of_agents*number_of_tasks, total_time).</p><p> This is returned only if detailed=True.  </p> </li> </ul> </li> <li> <p>individual_performance_t            : 1D numpy array </p> <ul> <li><p> The performance of each agent on the two different tasks, sum over time.  The shape is (number_of_agents*number_of_tasks,).</p><p> This is returned only if detailed=True. </p> </li> </ul> </li> </ul> <p></p>"},{"location":"plots/","title":"Plots","text":"<p>Utility for visualizing two\u2011task simulations: plots the time evolution of each agent\u2019s normalized task focus and optional task\u2011switch markers and cue overlay.</p>"},{"location":"plots/#-","title":"------------------------------------","text":""},{"location":"plots/#plot_curves","title":"<code>plot_curves(experiment,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 simulation_results,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 title=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 x_label=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 y_label=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_labels=None,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_legend=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_location='inside',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 legend_fontsize=10,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_vertical_lines=True,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_linewidth=1,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_line_color='black',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_switching_line_style='--',\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 show_cue_vector=False,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 scale_cue_vector=1,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 **kwargs)</code>","text":"<p>Plots simulation curves for a two-task experiment, specifically the time evolution  of the normalized difference between the two task activities for each agent. </p> <p>Parameters</p> <ul> <li> <p>experiment            : Experiment class object </p> <ul> <li><p> The experiment object that generated the simulation_results.</p> </li> </ul> </li> <li> <p>simulation_results            : 2D numpy array </p> <ul> <li><p> The simulation results use to create the plot.  The shape should be (number_of_agents * number_of_tasks, total_time).</p><p> The order is [agent1_task1, agent1_task2, agent2_task1, agent2_task2, ...] in case of two agents and two tasks.</p> </li> </ul> </li> <li> <p>title            : str, optional </p> <ul> <li><p> The title of the plot. The default is None.</p> </li> </ul> </li> <li> <p>x_label            : str, optional </p> <ul> <li><p> The x-axis label. The default is None.</p> </li> </ul> </li> <li> <p>y_label            : str, optional </p> <ul> <li><p> The y-axis label. The default is None.</p> </li> </ul> </li> <li> <p>legend_labels            : list of str, optional </p> <ul> <li><p> The labels for the legend. The default 'Agent i+1' whit i in range(number_of_agents).</p> </li> </ul> </li> <li> <p>show_legend            : bool, optional </p> <ul> <li><p> Whether to show the legend. The default is False (the legend is not shown).</p> </li> </ul> </li> <li> <p>legend_location            : str, optional </p> <ul> <li><p> The location of the legend. The default is 'inside' (the legend is inside the plot).  If 'outside', the legend is outside the plot.</p> </li> </ul> </li> <li> <p>legend_fontsize            : int, optional </p> <ul> <li><p> The font size of the legend. The default is 10.</p> </li> </ul> </li> <li> <p>show_vertical_lines            : bool, optional </p> <ul> <li><p> Whether to show vertical lines for task-switching times. The default is True  (the vertical lines are plotted).</p> </li> </ul> </li> <li> <p>task_switching_linewidth            : int, optional </p> <ul> <li><p> The width of the task-switching vertical lines. The default is 1.</p> </li> </ul> </li> <li> <p>task_switching_line_color            : str, optional </p> <ul> <li><p> The color of the task-switching vertical lines. The default is 'black'. </p> </li> </ul> </li> <li> <p>task_switching_line_style            : str, optional </p> <ul> <li><p> The line style of the task-switching vertical lines. The default is '--'.</p> </li> </ul> </li> <li> <p>show_cue_vector            : bool, optional </p> <ul> <li><p> Whether to plot the cue vector. The default is False (the cue vector is not plotted).</p> </li> </ul> </li> <li> <p>scale_cue_vector            : float, optional </p> <ul> <li><p> A scaling factor for the cue vector to make it more visible in the plot. The default is 1.</p> </li> </ul> </li> <li> <p>kwargs            : dictionary, optional </p> <ul> <li><p> Additional keyword arguments to pass to the plot function (e.g., color, linestyle, etc.).</p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/","title":"Utils","text":"<p>Utility functions for constructing agent gain vectors, the forward interaction matrix, and the cue vector used in the experiment.</p>"},{"location":"utils/#-","title":"------------------------------------","text":""},{"location":"utils/#gaussian_g_vector","title":"<code>gaussian_g_vector(average,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 deviation,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents)</code>","text":"<p>Create a vector of g values following Gaussian distribution. The average value of the vector is forced to be the average value given as input. </p> <p>Parameters</p> <ul> <li> <p>average            : float </p> <ul> <li><p> The average value of the Gaussian distribution.</p><p> The average should be greater than 0.0.</p> </li> </ul> </li> <li> <p>deviation            : float </p> <ul> <li><p> The standard deviation of the Gaussian distribution.</p><p> The deviation should be non-negative.</p> </li> </ul> </li> <li> <p>number_of_agents            : int </p> <ul> <li><p> The number of agents in the system.  The number of agents should be greater than 0.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>g            : 1D numpy array </p> <ul> <li><p> A numpy array of size (number_of_agents,) with the g values for all agents in the system.</p><p> All g values are non-negative. The average value of the g vector is equal to the average value given as input.          </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#-_1","title":"------------------------------------","text":""},{"location":"utils/#uniform_g_vector","title":"<code>uniform_g_vector(average,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_agents)</code>","text":"<p>Create a vector of g values following uniform distribution. The average value of the vector is forced to be the average value given as input. </p> <p>Parameters</p> <ul> <li> <p>average            : float </p> <ul> <li><p> The average value of the uniform distribution.</p><p> The average should be greater than 0.0.</p> </li> </ul> </li> <li> <p>delta            : float </p> <ul> <li><p> The deviation of the uniform distribution.</p><p> The deviation should be non-negative. The deviation should be less or equal to the average.</p> </li> </ul> </li> <li> <p>number_of_agents            : int </p> <ul> <li><p> The number of agents in the system.</p><p> The number of agents should be greater than 0.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>g            : 1D numpy array </p> <ul> <li><p> A numpy array of size (number_of_agents,) with the g values for all agents in the system.  All g values are non-negative. The average value of the g vector is equal to the average value given as input.       </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#-_2","title":"------------------------------------","text":""},{"location":"utils/#build_forward_matrix","title":"<code>build_forward_matrix(number_of_agent,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 alpha,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 beta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 gamma,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 delta,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 task_graph,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 communication_graph)</code>","text":"<p>Build the forward matrix of the system, where the parameter alpha, beta,  gamma and delta are the same for all the agents.</p> <p>The forward matrix is a matrix of size (Na * No, Na * No), where Na is the number of agents and No is the number of tasks. The forward matrix represents the interaction between all agents  and tasks. The next state of the agents is given by the matrix-vector product of the forward matrix and the current state of the agents, besides other terms.</p> <p>The basic formulas to get the forward matrix is: alpha * I + beta * (1 - I)   for the in-diagonal block gamma * I + delta * (1 - I)  for the out-diagonal block</p> <p>A more advanced formulas that use the graphs is the following: alpha * (G_o * I_o) + beta * (G_o - G_o * I_o)   for the in-diagonal block gamma * (G_o * I_o) + delta * (G_o - G_o * I_o)  for the out-diagonal block where G_o is the task graph, and I_o is the identity matrix of size No.</p> <p>Furthermore, each block is multiplied by their corresponding scalar value in the communication graph G_a.</p> <p></p> <p>Parameters</p> <ul> <li> <p>number_of_agent            : int </p> <ul> <li><p> Number of agents in the system.  The number of agents should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_tasks            : int </p> <ul> <li><p> Number of tasks the agents have to perform.  The number of tasks should be greater than 0.</p> </li> </ul> </li> <li> <p>alpha            : float </p> <ul> <li><p> The scalar value that weights the same agent-same task interaction.  The value should be non-negative.</p> </li> </ul> </li> <li> <p>beta            : float </p> <ul> <li><p> The scalar value that weights the same agent-different task interaction.</p><p> The value should be non-negative.    </p> </li> </ul> </li> <li> <p>gamma            : float </p> <ul> <li><p> The scalar value that weights the different agent-same task interaction.</p><p> The value should be non-negative.</p> </li> </ul> </li> <li> <p>delta            : float </p> <ul> <li><p> The scalar value that weights the different agent-different task interaction.    The value should be non-negative.</p> </li> </ul> </li> <li> <p>task_graph            : 2D numpy array </p> <ul> <li><p> The graph between tasks. A positive value means that the tasks are positively correlated,  a negative value means that the tasks are negatively correlated.  A null value means that the tasks are not correlated.</p><p> The task graph should be of size (No, No).</p> </li> </ul> </li> <li> <p>communication_graph            : 2D numpy array </p> <ul> <li><p> The graph between agents. A positive value means that the agents have a positive interaction,  a negative value means that the agents have a negative interaction.  A null value means that the agents can not communicate.</p><p> The communication graph should be of size (Na, Na).</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>F            : 2D numpy array </p> <ul> <li><p> The forward matrix of the system representing the interactions  between agents and tasks. The forward matrix is of size (Na * No, Na * No). </p> </li> </ul> </li> </ul> <p></p>"},{"location":"utils/#-_3","title":"------------------------------------","text":""},{"location":"utils/#build_cue_vector","title":"<code>build_cue_vector(number_of_agents,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_tasks,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_informed,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 number_of_switches,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 total_time,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 initial_steps=0,\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0\u00a0 reversed=False)</code>","text":"<p>Build the cue vector for the experiment. The cue vector is a 2D vector of size (total_time, Na * No)  that informs the agents about the tasks they should perform at each time unit.  Na is the number of agents and No is the number of tasks.</p> <p>The cue vector has the following characteristics:  - The first initial_steps time units are vectors of zero, meaning no tasks are prioritized for all agents.  - After, the cue vector has a step function shape with n_switches regular steps, indeed leading agents to switch tasks at regular intervals. Every step has the same length given by  (total_time - initial_steps) // number_of_switches.  - The first switching step is a vector of 1 for the first task and -1 for all the other tasks, meaning that Task 1 is prioratized.  - The vector is then rotated by one position for each step, meaning that now Task 2 is prioratized. etc.  - When reversed is True, the cue vector is reversed.  - The informed agents are the first number_of_informed agents in the system and are the only ones  receiving the task cue. For the other agents, the cue vector elements are zeros.</p> <p></p> <p>Parameters</p> <ul> <li> <p>number_of_agents            : int </p> <ul> <li><p> Number of agents in the system.  The number of agents should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_tasks            : int </p> <ul> <li><p> Number of tasks the agents have to perform.  The number of tasks should be greater than 0.</p> </li> </ul> </li> <li> <p>number_of_informed            : int </p> <ul> <li><p> Number of agents that are informed about the tasks (that receive the task cue).  The number of informed agents should be non-negative and less than or equal to the number  of agents.</p> </li> </ul> </li> <li> <p>number_of_switches            : int </p> <ul> <li><p> Number of switches in the cue vector.</p><p> The number of switches should be positive.</p><p> The number of switches should be less than or equal to total_time - initial_steps.</p> </li> </ul> </li> <li> <p>total_time            : int </p> <ul> <li><p> Total time of the experiment in time units.  The total time should be greater than 0.</p> </li> </ul> </li> <li> <p>initial_steps            : int, optional </p> <ul> <li><p> Number of initial time steps where no task is prioritized.  The number of initial steps should be non-negative.</p><p> The number of initial steps should be less than or equal to total_time.</p><p> Default is 0.</p> </li> </ul> </li> <li> <p>reversed            : bool, optional </p> <ul> <li><p> This options is used to reverse the cue vector. If True, the cue vector is reversed.</p><p> Default is False.   This option should be used only when the number of tasks is 2.</p> </li> </ul> </li> </ul> <p>Return</p> <ul> <li> <p>cue_vector            : 2D numpy array </p> <ul> <li><p> The cue vector of the experiment. The cue vector is of size (total_time, Na * No).</p><p> The cue vector informs the agents about the tasks they should perform at each time unit.</p><p> The cue vector is the same for all agents, except for the uninformed agents that have a cue vector of zeros.</p> </li> </ul> </li> </ul> <p></p>"}]}